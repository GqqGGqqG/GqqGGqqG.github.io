{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"about","text":"NEWS简介标准小镇做题家， 间歇性踌躇满志， 专业表演退堂鼓，AKA talked five 学历2014-2017 高中 江西省九江市庐山市一中 理科（rank1） 2017-2021 本科 武汉大学计算机学院 软件工程（3.875/4.0 8/58 14/316） 2021-202? 硕士 武汉大学计算机学院 计算机科学与技术 获奖2017-2018 武汉大学国家励志奖学金 武汉大学优秀本科生丙等奖学金 2018-2019 武汉大学国家励志奖学金 武汉大学优秀本科生丙等奖学金 2019-2020 武汉大学国家励志奖学金 武汉大学优秀本科生丙等奖学金 联系Github: https://github.com/GqqGGqqG LeetCode: https://leetcode-cn.com/u/gqqggqqg/ AcWing: https://www.acwing.com/user/myspace/index/91541/ Email: gqzooo@qq.com QQ: 884427437","link":"/about/index.html"}],"posts":[{"title":"浮生物语21-03","text":"主要内容： 日常 学习 2021-03-15基金最近大跌，亏了许多（目前累计-2000），做好长线投资准备，切忌追涨。 这两天睡觉时间都不是很规律，精神不太好，需要尽快调整。 2021-03-16今日发现毕设一处存在比较的不公平问题，不该用ISTD+作为训练，头大，部分实验需要重新跑一遍，帮室友开了colabpro，这下用两个colab一起跑，不知道够不够用。 先两个网络一起跑（这钵是左右开弓），看一下带有resnet的阴影去除和不带resnet的阴影去除，但是两个都带了CBAM模块，两者之间的差距。 不过好在需要跑的网络也就SYN（3）,SYN-ISTD（1.5）,SBU（3）,ISTD（3/0）,SYN-SBU（1.5）, 两个colab一个星期左右就能训练完。所以还是得在23号之前完全确定使用什么模型，如果来个SRD就再加3天。 不过阴影检测确实是好的离谱（可能是增强数据集，不过也和2020年的差不多了，实在搞不清楚为什么这么强），咋阴影去除就这么拉跨捏。 如今优毕就在眼前，我必须考虑这是不是我此生仅有的机会。 重铸科研荣光，我辈义不容辞！ 比原网络性能好就算成功！ 2021-03-17今日毕设实验还算成功，至少可以确定比之前的网络性能好，但是两个仅仅是在阴影去除不同配置的网络，阴影检测的效果却差了很多。并且好的阴影检测效果带来的是差的阴影去除效果。但是之前跑的那次在ISTD+上继承训练了ISTD的网络的效果也不错，最后应该都还没收敛。 才发现输出的阴影结果不是0或255，是之间的数，还得做下处理(不过我研究了下，代码里面有个大于125的视为阴影）。看了下，如果是自己配置一个数字结果更加夸张的好，还是保持原样不变吧。 mtmt是用的128，反正大概也差不多 不过记得最后演示结果的时候把它转成125吧。 顺便跑了下SBU的阴影去除，后面检测SBU还是会用的，引用了DHAN（怎么会有人把RGB转成BGR作为输入的啊，导出的时候还得转一下，半天没找出来什么问题） 实验方案： 继续训练那个好的阴影检测网络效果，看是否是epoch不足导致模型未收敛（希望吧，训练一个晚上应该差不多了） 单独测试阴影去除网络配置能否提升整体效果（后续这个实验以后还是会做的） 2021-3-18突然的一个loss下降，保持了200轮的4.2左右下降到了3.5，我人傻了，这大概是600轮左右的时候，有、吓人，跑出来的数据应该很好吧。 但是600轮的检测结果比200轮的差，去除结果比它好，但是还是挺差的。再训练一下看下吧，不应该啊，决定调高学习率（2e-4 -&gt; 2e-3），跳出局部收敛点,50轮保存模型再重新训练。 玩崩了，干脆重新训练一遍（Discriminator的loss无法收敛了，训练下去只会是D的优势，历史的经验告诉我们，不要随便改那些参数，因为你永远不知道别人做了多少试错的工作） 可以尝试下调低batchsize，或者干脆保存下模型~ 4.29的时候测试一下 对于shadowremoval不好的情况，可以自定义resnet的结构（将开始的3改成4 即可） 毕设网络结构三选一 respam+pam （结果是比原模型好的，反正已经算毕业了） respam+respam（用的一个1*1卷积） respam+respam（直接更改res_fork的结构，把3修改为4，并且记得不要导入模型文件即可。） 2021-03-19respam+respam那个1*1的卷积效果导致阴影去除的效果不好，比原模型要差一点（估计还是因为1 ** 1 的卷积导致了数据降维，丢失了一部分语义信息），之前好的数据可能是因为无意识下做了数据增强，用了ISTD+作为了训练集。 更改了shadow——removal的结构后，收敛缓慢，因为需要重新训练一整个resnet101，所以做出修改，只针对第一个conv操作，把它的输入从3修改到4即可（计划通）。 不过记得其它的地方（其它的模型都没有pre这个参数，需要统一一下，或者管理一下名字）需要和这个地方一致就是了，管理起来混很麻烦，记得做好备注。 如果一切顺利，这应该是效果最好的一个版本，也不带pam模块，直接训练，冲就vans了 今天基金亏了2个点，又是200多，这周好像还亏100多。 2021-3-20leetcode大无语事件 在leetcode的playground里面试了一下，两个环境能输出两个结果我是服气的(后面仔细看了下，原来我交的题目是python环境不是python3，大意了) 不过在自己的环境里面试了一下，这个负数的除法确实是得好好研究下 结果如下 4.30的版本是第275个epoch的，因为280的时候loss突然下降，防止又是过拟合了 讲座:教授迟到了一个小时，还得早上早起去听。讲的是粒子群优化之类的智能计算问题，虽然核心我听不懂，但是我感觉，它的思路就是针对特定的问题，使用现有的模型并对此提出一种新的思路，稍作修改让它能够胜于其它的一些模型。（在新的问题上用旧的思路） colab限额了，坏起来了，仁杰的账号连续跑了五天，我感觉是colab不允许用户每天都在跑，长时间跑。所以我们换着用吧，这个限额用那个，不要一起跑就是了。 RES3RES4NOPAM(并且还没有最终收敛，应该还可以再跑一跑)的结果还不错，阴影去除会比原网络要好（论文里面的，还不仅仅是跑出来的结果），现在只需要说明RES3的结果不比上面的好，以及RES4的结果比原文好，以及PAMPAM会带来正增益即可，不过阴影检测又刷新了记录，真愁人啊。 需要证明的点 RES3RES4&gt;RES3orRES4&gt;ORIORI PAMPAM&gt;ORIORI RES3PAMRES4PAM&gt;RES3RES4 训练计划： 训练50轮RES3RES4看下结果（尤其是阴影检测）能不能稍微差点，不然后面不好发挥 训练RES3ORI(稍微差点)，ORIRES4(要好)，能否比ori好以及比RES3RES4差 继续训练PAMPAM（继续训练，已经训练了450轮，再来250轮左右？），比原来的好就行 训练RES3PAMRES4PAM,最好的结果 训练SBU 训练SRD（选择性放弃？） 2021-3-21训练起来真麻烦，我又不能保存所有的模型，GAN网络训练起来浮动又很大。（最好笑的事情是，我对shadow removal模块做了修改（ORIRES4），detection没动，最后的结果反而让detection的效果变好，removal的效果变差）干脆直接确定最后一个版本，最后使用一个SYN进行优化吧，几个网络结构的对比就不用了吧（随机性太大，pre的初始也有随机，不同模块的随机也一定）。 下一步为了防止过拟合250，300，350，400，450，500。五个版本的模型都保存看一下吧，训练到600多的感觉好像都不太行（训练太多反而会导致过拟合） 自己写了个测试测试集的代码，不知道为什么他没写，我也没注意，对于G2的loss，我们输入的是gt作为输入而不是G1产生的shadow，防止产生影响。 25号之前一定要确定模型惹，加油啊 2021-3-22大无语事件 原模型是输入256，输出也是256，阴影检测resize到原尺寸倒无所谓，阴影去除resize到原尺寸会使用LANZOS插值，肯定会有损失的sa。学姐和我说把gt resize到256再作比较。（这样一看，我的shadow removal就有增益惹（1%的增益，蚊子再小也是块肉嘛），make sense） 它的代码没有val集的loss估计，还得我重新写了个，我才发现200轮左右loss就差不多了。还需要训练那么多轮？yeah，结果比较明朗了，把剩下的实验做一做就vans了嗷 晚上闲着无聊开了两个箱子，真出啊就？ 今天要开始断电了，晚上还得关机，真实思路打断器，第二天早上起来还要开个机重新打开IDE，真的有够麻烦的。 2021-3-23今天还是想试验一下pamboth能不能给两个任务带来收益，但是经过上午的观察，对detection没有收益，而对removal还有一点点收益，还得仔细考究一下（实在不行，咱就不加上去了吧，我感觉我那样改应该也够用了）。 所以还是先把需要做的实验先给做了吧（RES3先给做了，pam什么的观察下有没有用再说吧（看下ori对于val的loss情况就应该清楚了）） 2021-3-25二元数组排序，非常的好用（默认从小到大排） 1res_tempt.sort(key = lambda x:(x[1],x[0])) 毕设上非常麻烦的事情就是因为removal网络的优化只有2%左右，因此两个网络训练的结果不一定比一个网络好，根本不能判断removal网络到底是好还是坏，今天训练的结果就不算理想。还是得多训练一下看看结果吧。 2021-3-26结果还算不错，ISTD以及相应的网络结构的去除都做完了。现在先把SBU和SRD（测试，如果不理想就用ISTD+，因为没有给出测试集）。然后再做SYN数据集和ISTD和SBU的训练测试。Fighting！！！明天记得把审稿任务的文档做完给老师。 2021-3-29实验滑铁卢！SBU的训练出来的数据还有没文章的数据好，查看了下数据的特征 9.0 22.0 2.0 （All，S，NS 非常明显的就是很多阴影没有检测到，初步猜测是因为用DHAN做SBU的removal效果不是很好（1是它的阴影检测不太行，2是阴影去除的尺寸对不上，所以导致阴影去除反向影响了阴影检测。所以今天把模型删了一半，把阴影检测单独ling出来训练，现在35轮看起来还不错的样子。明天应该能训练一个初步的模型出来。 或者说bs为4的时候也可能导致训练动荡？可是我都训练200轮了，换算到ISTD都有600轮了，也不应该啊。 如果实在不行，就用ISTD-trained的模型作预测吧，反正原来的论文里面也有这个数据，可以用来作对比（就是不知道效果怎么样），反正这是下下策了。 2021-3-31用ISTD-trained的模型作预测发现和原论文数据差不多，并没有什么用 单独对阴影检测进行训练，发现同样的loss的情况下，也能出现比原文好的数据，也能出现和原文差不多的数据。不过至少算是有进步了吧。稍微做下训练，实在不行就用比原文好的数据。（因为好的也不是很多 17%左右吧 把batchsize调到4再跑50轮看看吧 顺便SYN数据集也开始做训练了，至少两个一起跑后面就不会仓促了","link":"/2021/03/15/%E6%B5%AE%E7%94%9F%E7%89%A9%E8%AF%AD21-03/"},{"title":"2020-3学习","text":"主要内容： 学习 吴恩达 吴恩达逻辑回归 sigmoid 激活函数 将结果映射到0-1之间 ，hypothesis h(x)输出概率 决策边界 设置一个threshold 当概率大于t时预测为y=1,反之为0 当在sigmoid函数中设置为0.5时，只需要theta X大于0即预测为正例 线性边界： x1+x2+…+xn&gt;=1 非线性边界：x1^2 +x2^2+…+xn&gt;=1 代价函数 单纯使用平方代价函数会导致损失函数（因为sigmoid为非凸函数）变成非凸函数，使得损失函数有多个局部收敛点，希望能够尽量让损失函数只有一个收敛点。 解决方法 好处： 当样本y=1时，预测为0，损失为0，预测为1，损失为无穷 凸函数 简化代价函数和梯度下降 将上述的代价函数简写,和GAN网络的代价函数很像 y=0 时 1-y = 1反之亦然 梯度下降与线性回归中的类似，但是由于h（x）不是一个操作，所以并不等价 高级优化 一些高级的优化算法 选择合适的学习率，加快收敛速度 多元分类：一对多 上面讲的只是二分类，实际场景内有许多的类别需要我们来预测 ​ 1.Ova/r 对于n（n&gt;=3）个类训练n个分类器 将不属于该类的都归于负类 最后的输出结果为三个分类器中的最大值，最大值即为最终的分类 OvO 此时的结果为投票取最多的结果 n&gt;=3 OVO OVR 模型数目 n*(n-1)/2 n 时间 长 短 准确率 高 低 策略 选取所有分类器中最大次数预测结果 选取n个分类器中最大值对应的分类器的正值 分类器的不同 线性网络分类器 神经网络分类器 方法 二分类演化 softmax 效果 差（因为是线性，有局限） 好 正则化 过拟合问题 欠拟合：预测与真实有较大差距","link":"/2021/03/14/2020-3%E5%AD%A6%E4%B9%A0/"},{"title":"浮生物语21-04","text":"主要内容： 学习 2021-04-01学姐也没有什么办法能够解决SBU的训练问题 SBU： 方法1：直接和源论文在SBU上训练的数据作对比，但是SYN数据集可能没有办法用上去。（不太喜欢 方法2：也将STCGAN的detection独立出来，单独作训练并且对比（如果时间比较多） 方法3：直接不比较了（如果时间来不及的话 SRD： 因为STCGAN没有训练SRD，没有一个数据能够进行对比，所以应该不进行比较了。但是如果时间够的话也可以训练一下看下数据怎么样。（训练数据可以用我们的Detector进行检测出来）不过很多文章都没有用SRD，其实可以不比较，因为原文也没有。 目前的训练计划： 先训练SYN，再训练SYN-ISTD 然后训练SBU(之前一个太好了可以让它变差一点)看看后面的结果能不能变好，争取8号之前完成所有实验，srd可以直接用ISTD作对比，反正原文没有这个数据，没有优化就不用了，20号之前写完论文查重 2021-04-04看了下，我估计SBU表现差的原因是SBU的GT其实出现了非常多的漏标，所以结果不好，最近花时间把严重漏标的数据删除一下。 然后今天SYN数据集做预训练在ISTD（我估计是因为源论文做阴影生成都是onthefly的）上表现其实也不怎么样，阴影检测没什么突破，阴影去除稍微好了点（10-15号做下训练吧），反正也不是自己的创新点，加进去感觉也没什么用。所以这两天的重心还是把SBU和SRD训练出来，至少论文的数据就有了，然后开始写论文吧。 SRD在张玲学姐的论文里有数据，引用一下就好了。 2021-04-05晴天大霹雳！ 今天把SRD训练结果做出来了，以及SBU删除了1200张图片（一股辛酸泪啊，删了四天）然后上传做了继承训练。估计很快这些结果就都能出来(如果实在不行，就用那个6.0的数据吧)。 不过今天仔细看论文的时候看了眼它的损失函数，它做阴影检测的时候用的是BCEloss（因为本质上它也是一个二分类的问题），做阴影去除的时候用的是L1Loss，但是那个人的代码是在阴影检测上用的L1Loss，不知道它对结果会不会有影响。 4.7号之前做完所有实验收尾开始写论文，然后开始重新做这组实验吧，预训练的数据集就不用了，估计是用不上了，也不是自己的工作量。 阴影检测还得resize到原尺寸做一下，不然我感觉不是很严谨 在论文里面可以用SBU，SRD，但是图片用不了，因为原文也没有提供。不过可以直接使用ISTD训练的模型，说我自己没时间做它的训练了，但是数据仍然是文章所提供的数据。 但是我自己并不是很想用，所以在结果里面只用ISTD好了，一了百了，yeah。 任务 训练完毕SBU 测试SRD，SBU结果 写论文，重新训练五个模型（RES4,RES3,RES3RES4,SBU,SRD）","link":"/2021/04/01/%E6%B5%AE%E7%94%9F%E7%89%A9%E8%AF%AD21-04/"},{"title":"21-04-刷题","text":"主要内容： acwing, 数组，字符串，基础课 如何导入一行的变量 123int a，b;cin&gt;&gt;a&gt;&gt;b;//input &quot;2 3&quot; 如何导入多维数组 1234567891011int li[n][m];for(int i = 0;i&lt;n;i++){ for(int j= 0;j&lt;m;j++){ scanf(&quot;%d&quot;,&amp;li[i][j]); //cin&gt;&gt;li[i][j] 也可以 }}//input//1 2 3//4 5 6//7 8 9 如何使用pow 1234#include&lt;cmath&gt;//等价于#include&lt;math.h&gt;int a = pow(3,2)//3**2 = 9 多行数字输入，以0时结束 123456789int n;while(cin&gt;&gt;n,n){ //0 为false 故不会进入 cout&lt;&lt;n&lt;&lt;endl;}//input //1//2//0 初始化问题 全局变量数组随机初始化时会为0 函数内数组随机初始化为随机 但是可以像一维数组一样对二维数组初始化 12345678910111213141516171819202122#include&lt;iostream&gt;using namespace std;int li_a[3][3];int main(){ int li_b[3][3]; //int li_b[3][3] = {0}; 这样结果就是对的 for(int i=0;i&lt;3;i++){ for(int j=0;j&lt;3;j++){ printf(&quot;%12d&quot;,li_a[i][j]); //all will be equal to 0 } cout&lt;&lt;endl; } cout&lt;&lt;endl; for(int i=0;i&lt;3;i++){ for(int j=0;j&lt;3;j++){ printf(&quot;%12d&quot;,li_b[i][j]); //random(int) } cout&lt;&lt;endl; }} c++字符串的初始化 1234char s[] = {'a','b','c'};char s1[] = {'a','b','c','\\0'};char s2[] = &quot;abc&quot;;//结果是一样的 c++字符串的读入输出 123456789101112131415161718192021222324char s[4];//读入以 空格或回车为结束cin&gt;&gt;s;cin&gt;&gt;s+1;//因为是指针，不需要引用scanf(&quot;%s&quot;,s);//从某个下标读取 ,cpp的指针运算机制scanf(&quot;%s&quot;,s+1);//空格同时读入 1000000为最多读入多少字符//字符数组fgets(s,10000000,stdin);cin.getline(s,10000000);//string#include&lt;cstring&gt;string str;getline(cin,str);;//输出cout&lt;&lt;s;cout&lt;&lt;s+1;printf(&quot;%s&quot;,s);//从某一下标开始输出printf(&quot;%s&quot;,s+1); 字符串常见操作 仅对于char数组 123456789//string.h/cstring#include&lt;string.h&gt;#include&lt;cstring&gt;//返回数组长度strlen(str);//比较字典序 若str1&lt;str2 -1 == 0 &gt;1strcmp(str1,str2);//char数组拷贝 把b拷贝给astrcp(a,b); segment fault 12345char c;//会出错，因为类型不对printf(&quot;%s&quot;,c);//correctionprintf(&quot;%c&quot;,c); 本质上的区别 读到回车时下面会多读一次，i会再次加一 12while(cin&gt;&gt;a[i]) i++;while(cin&gt;&gt;a[i++]); 字符串的操作 1234567string s;s.size();s.length();//从下标0开始，截取s.size()-个字符s.substr(0,s.size()-1);//从下标5开始，一直到结束s.substr(5); ACWING \\777. 字符串乘方 https://www.acwing.com/problem/content/779/ 字符串长度n 枚举n的约数 再将可能的排列扩大到n，判断是否与原字符串相等。 人家的代码写的多好看啊~ ACWING \\778. 字符串最大跨距 https://www.acwing.com/problem/content/780/ 很有意思，自己写的很臭 如果用库函数肯定很快 记得str.size()返回的是一个unsigned int，做运算时会把int强转ui，要么把它转int，要么就特判。 函数定义 1234567891011121314151617181920//函数声明 可以不写变量名称 算法题一般用不到int foo(int);//函数定义 形参int foo(int n){//donothing//不写return时会随机返回数值}//默认参数 但是只能出现在后方并且连续int foo(int a,int b=10){}//random()cout&lt;&lt;foo();//实参int foo1(int &amp;n);int foo1(int &amp;n){} 静态变量的初始化只会在第一次被执行 和全局变量一样，都会被赋值为0 1234567//仅在函数内部能被访问到的全局变量int foo(){ static int cnt; cout&lt;&lt;cnt++&lt;&lt;endl;}foo()*5; AcWing \\808. 最大公约数 https://www.acwing.com/problem/content/810/ 12345678910111213141516171819202122//辗转相除int gcd(int a,int b){ if(a%b==0) return b; return gcd(b,a%b);}//非递归 可以加入判断大小swap()#include&lt;algorithm&gt;int gcd(int a,int b){ int tempt; while(a%b!=0){ tempt = a%b; a = b; b = tempt; } return b;}//双击666int gcd(int a,int b){ while(b^=a^=b^=a%=b); return a;} 多维数组的第一维的参数可以去掉 1234int foo(int li[][3][4]){ return 0;}foo(newli); sizeof对于数组参数的影响； 1234567891011121314#include&lt;iostream&gt;using namespace std;void foo(int b[]){ cout&lt;&lt;&quot;IN_FUNC &quot;&lt;&lt; sizeof(b)&lt;&lt;endl;}int main(){ int a[] = {1,2,3,4,5,6}; //sizeof a 是对的 cout&lt;&lt;&quot;IN_MAIN &quot;&lt;&lt; sizeof a&lt;&lt;endl; foo(a);}//IN_MAIN 24//IN_FUNC 8 快速排序 这是别人写的 边界分析 123456789101112//重点是特判、i，j的初始化 、以及边界处理，背！void quick_sort(int q[],int l,int r){ if(l&gt;=r)return; int i = l-1,j = r+1; int x = q[l+r&gt;&gt;1]; while(i&lt;j){ while(q[++i]&lt;x); while(q[--j]&gt;x); if(i&lt;j)swap(q[i],q[j]); } quick_sort(q,l,j);quick_sort(q,j+1,r);}","link":"/2021/04/26/21-04-%E5%88%B7%E9%A2%98/"},{"title":"快速排序实现与分析","text":"主要内容： 快速排序算法的实现与细节分析，参考 1234567891011//先上代码void quick_sort(int q[],int l,int r){ if (l&gt;=r)return; int i = l-1,j = r+1,x = q[l+r&gt;&gt;1]; while (i&lt;j){//eq3 while(q[++i]&lt;x);//eq1 while(q[--j]&gt;x);//eq2 if(i&lt;j)swap(q[i],q[j]); } quick_sort(q,l,j);quick_sort(q,j+1,r);} 输入分析：q[l~r] 输入的为数组指针q，从l开始到r结束的闭区间数组，对其中的元素进行排序 递归终止：if(l&gt;=r)return; 当输入的数组长度为0，1时，必定有序，则无需进行排序操作，防止了无限递归。 i，j初始化：int i = l-1,j = r+1; 将所有i，j可能的数值进行统一处理，而不必先判断当前的i是否为0。 小循环终止条件 while(q[++i]&lt;x); while(q[–j]&gt;x); ++i保证i会持续向后移动 当终止条件为&lt;=x时，会出现无限月读的情况，因为==x的元素永远不会移动 x取值 int x = q[l+r&gt;&gt;1]; 取中间保证不会受到有序的数组的特殊情况导致超时的现象 向下取整保证x的选取不会为q[r]（会出现无限月读），但数值可以相同 划分有效性证明：（l,j）(j+1,r)的划分中，lj为&lt;=x ,j+1r为&gt;=x 由eq1,eq2得 q[l,i-1]&lt;x and q[i]&gt;=x ① q[j+1,r]&gt;x and q[j]&lt;=x ② 由eq3得 i&gt;=j ③ 由①③有 q[l,i-1]&lt;x i&gt;=j ==&gt;&gt; i-1&gt;=j-1 q[l,j-1]&lt;x ④ 由④②有 q[l,j-1]&lt;x q[j]&lt;=x q[l,j]&lt;=x 恒成立 而 q[j+1,r]&gt;x ==》 q[j+1,r]&gt;=x （充分条件） 综上，故有 **q[l,j]&lt;=x q[j+1,r]&gt;=x **恒成立 划分正确性证明： j==r时出现的无限月读 当j==r时，右数组长度为0，故没有出现有效划分 而j==[l,r-1]时，至少都会划分出长度为1的数组，故有效 故需要验证不会出现无限月读，即划分结果中出现 j！=r，即j的值域需要映射在[l,r-1] 证明j&lt;r 当j==r时 根据上面的推论 q[r]&lt;=x i&gt;=j =&gt; i&gt;=r q[i]&gt;=x q[l,i-1]&lt;x q[r]&gt;=x q[l,r-1]&lt;x 故q[r] = x 而x = q[l+r&gt;&gt;1],其数组长度&gt;=2，并且向下取整的机制保证l+r&gt;&gt;1在 （l,r-1）内而不可能=x，故j!=r 证明j&gt;=l 当j&lt;l时 根据上面的推论 q[l,r]&lt;x恒成立，而x取自于（l，r)，故j&gt;=l","link":"/2021/04/30/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E5%AE%9E%E7%8E%B0%E4%B8%8E%E5%88%86%E6%9E%90/"},{"title":"配置博客及图床","text":"主要内容： 腾讯云 chevereto 图床 typora配置 购买腾讯云服务器及域名腾讯云用于做图床服务器，如果使用github或者gitee或者其它第三方服务做图床，可以不使用。（配置选学生机最低档即可，106元一年） 购买域名用于映射xxxx.github.io, 更好记忆与访问，不需要可以不购买。（6元一年） 对域名申请ssl证书，用于部署图床的https访问。（免费，但安全等级不高，访问图床后端时还是会提示不安全） 部署chevereto傻瓜式的方法为安装宝塔，再根据步骤[1]安装chevereto即可，是社区访问还是个人使用请自行配置。默认配置为http访问，可以用于md文档的预览，但是在后续的部署上，个人博客网站为https访问，无法加载http资源的图床内容。所以需要在chevereto的设置栏中设置为https访问，以及将域名的ssl证书上传，配置nginx的https服务。 [1] ：https://blog.csdn.net/qq_44022113/article/details/114239677 Typora配置首先安装picgo[1]，用于后台的图片上传工作，在typora的偏好，图像中选择上传服务设定，选择Picgo以及配置相应的路径。 在picgo中安装chevereto插件，并将chevereto作为默认上传服务以及关闭其它服务，在图床设置中配置url以及key，key为chevereto的仪表盘中的api选项[2]，可以使用默认api的key或自己定义。 验证图片上传选项时请确保打开了chevereto的上传权限，以及打开图片重命名的选项保证同一图片上传不会发生同名错误。 因为申请的是域名申请到的ssl证书，所以请使用dns解析将网站转发到服务器上，再使用网站的接口而不是服务器的接口，否则图片将无法在typora中预览。（ssl证书是网站的而不是服务器的） 配置完后请重启typora保证设置生效。 [1] ： https://molunerfinn.com/PicGo/ [2]： https://YOUR_IP/dashboard/settings/api 2021-04-30 更新 后续使用时发现存在以下问题 域名需要备案 备案流程极其复杂，需要到公安局申请 网页上需要加注审核号以及相关信息 综上，放弃使用域名以及自建图床的方法，使用SM.MS图床（唯一缺点，上限5G,不过如果超了的话换一个账号好了），域名采用github.io一了百了。 hexo使用tips 生成文档使用hexo n “title” 部署文档使用hexo g -d 但是每次更新还要打开命令行，就非常的不人性化 解决方法 将hexo g -d 封装为bat脚本 //使用vps封装该bat脚本，因为.run里面有个参数0，可以让该bat脚本执行时不开启窗口 DIM objShell set objShell=wscript.createObject(&quot;wscript.shell&quot;) iReturn=objShell.Run(&quot;cmd.exe /C E:\\files\\GQ_BLOG\\update.bat&quot;, 0, TRUE) windows任务计划程序里设置执行该脚本的计划，每一小时一次（参数里记得加入起始位置为这两个脚本所在的目录）。 换电脑的时候记得把这个计划给删了，不然两端的内容不一致就van了","link":"/2021/03/12/%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%9B%BE%E5%BA%8A/"}],"tags":[{"name":"技术","slug":"技术","link":"/tags/%E6%8A%80%E6%9C%AF/"},{"name":"学习","slug":"学习","link":"/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"网课","slug":"网课","link":"/tags/%E7%BD%91%E8%AF%BE/"},{"name":"吴恩达","slug":"吴恩达","link":"/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"},{"name":"浮生物语","slug":"浮生物语","link":"/tags/%E6%B5%AE%E7%94%9F%E7%89%A9%E8%AF%AD/"},{"name":"刷题","slug":"刷题","link":"/tags/%E5%88%B7%E9%A2%98/"},{"name":"acwing","slug":"acwing","link":"/tags/acwing/"},{"name":"排序","slug":"排序","link":"/tags/%E6%8E%92%E5%BA%8F/"},{"name":"经典算法","slug":"经典算法","link":"/tags/%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95/"}],"categories":[{"name":"技术","slug":"技术","link":"/categories/%E6%8A%80%E6%9C%AF/"},{"name":"学习","slug":"学习","link":"/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"日常","slug":"日常","link":"/categories/%E6%97%A5%E5%B8%B8/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"}]}